{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 404 Not Found\n",
    "# url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
    "\n",
    "# Instead, we can use:\n",
    "url = \"https://github.com/hwchase17/chroma-langchain/blob/master/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "    f.write(res.text)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk the data\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":51582},\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"address\":\"10.138.31.39:51583\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"address\":\"10.138.31.39:51582\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"action\":\"raft\",\"index\":9,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:10.138.31.39:51387}]]\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":11,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":11,\"time\":\"2024-07-27T19:04:40+09:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [10.138.31.39:51582]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"10.138.31.39:51582\"],\"time\":\"2024-07-27T19:04:41+09:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"10.138.31.39:51582\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"10.138.31.39:51582\"],\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":5,\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":5,\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"index\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-07-27T19:04:41+09:00\"}\n",
      "{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"index\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"address\":\"10.138.31.39:51582\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"index\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:ea51c4a5-6fd3-4e82-9aa4-5fade6bb17bf Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[]}\",\"time\":\"2024-07-27T19:04:42+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/objects/segment-1722074493600713000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/property_text/segment-1722074493603549000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/property_text_searchable/segment-1722074493604184000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/property_source/segment-1722074493604834000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/property_source_searchable/segment-1722074493605431000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_45a58b050105402da7eb98561cac87be\",\"index\":\"langchain_45a58b050105402da7eb98561cac87be\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_45a58b050105402da7eb98561cac87be/3xoWZnYMMtUM/lsm/property__id/segment-1722074493606064000\",\"shard\":\"3xoWZnYMMtUM\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-27T19:04:43+09:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_45a58b050105402da7eb98561cac87be_3xoWZnYMMtUM in 39.441584ms\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-27T19:04:43+09:00\",\"took\":75250}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/objects/segment-1722074559962954000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/property_text/segment-1722074559980632000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/property_text_searchable/segment-1722074559997665000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/property_source/segment-1722074560021898000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/property_source_searchable/segment-1722074560032123000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"index\":\"langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58/muBRMruusJTU/lsm/property__id/segment-1722074560011031000\",\"shard\":\"muBRMruusJTU\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-27T19:04:43+09:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_ebd0f7ef652b42a59d5e6b8fb7b2aa58_muBRMruusJTU in 32.533208ms\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-27T19:04:43+09:00\",\"took\":787792}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/objects/segment-1722074493903651000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/property_text/segment-1722074493905515000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/property_text_searchable/segment-1722074493905853000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/property_source/segment-1722074493906333000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/property_source_searchable/segment-1722074493906809000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"LangChain_89e4f50fd3cd4de6958652bca60a44bf\",\"index\":\"langchain_89e4f50fd3cd4de6958652bca60a44bf\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/judy/.local/share/weaviate/langchain_89e4f50fd3cd4de6958652bca60a44bf/jYLbysv3h8wa/lsm/property__id/segment-1722074493907293000\",\"shard\":\"jYLbysv3h8wa\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-27T19:04:43+09:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_89e4f50fd3cd4de6958652bca60a44bf_jYLbysv3h8wa in 31.190583ms\",\"time\":\"2024-07-27T19:04:43+09:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-27T19:04:43+09:00\",\"took\":39541}\n",
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/judy/.local/share/weaviate/langchain_13be5c6c874a4ff489d0f4437746e9c1/ZWaONRgwooca/proplengths does not exist, creating new tracker\",\"time\":\"2024-07-27T19:04:44+09:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-07-27T19:04:44+09:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_13be5c6c874a4ff489d0f4437746e9c1_ZWaONRgwooca in 1.537291ms\",\"time\":\"2024-07-27T19:04:44+09:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-27T19:04:44+09:00\",\"took\":50042}\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Setup vector database\n",
    "client = weaviate.Client(\n",
    "  embedded_options = EmbeddedOptions()\n",
    ")\n",
    "\n",
    "# Populate vector database\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    client = client,    \n",
    "    documents = chunks,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    by_text = False\n",
    ")\n",
    "\n",
    "# Define vectorstore as retriever to enable semantic search\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "# Define LLM (GPT)\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# If you want to use Ollama & Llama3:\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3:latest\")\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use two sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/opt/anaconda3/envs/ragas/lib/python3.9/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\"What did the president say about Justice Breyer?\", \n",
    "             \"What did the president say about Intel's CEO?\",\n",
    "             \"What did the president say about gun violence?\",\n",
    "            ]\n",
    "ground_truths = [[\"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\"],\n",
    "                [\"The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.\"],\n",
    "                [\"The president asked Congress to pass proven measures to reduce gun violence.\"]]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "  answers.append(rag_chain.invoke(query))\n",
    "  contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 12/12 [00:06<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What did the president say about Justice Breyer?</td>\n",
       "      <td>The president thanked Justice Stephen Breyer f...</td>\n",
       "      <td>[Tonight, I’d like to honor someone who has de...</td>\n",
       "      <td>[The president said that Justice Breyer has de...</td>\n",
       "      <td>The president said that Justice Breyer has ded...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.893595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did the president say about Intel's CEO?</td>\n",
       "      <td>The president mentions Intel's CEO, Pat Gelsin...</td>\n",
       "      <td>[But that’s just the beginning. \\n\\nIntel’s CE...</td>\n",
       "      <td>[The president said that Pat Gelsinger is read...</td>\n",
       "      <td>The president said that Pat Gelsinger is ready...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What did the president say about gun violence?</td>\n",
       "      <td>The president asked Congress to pass proven me...</td>\n",
       "      <td>[And I ask Congress to pass proven measures to...</td>\n",
       "      <td>[The president asked Congress to pass proven m...</td>\n",
       "      <td>The president asked Congress to pass proven me...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "0  What did the president say about Justice Breyer?   \n",
       "1     What did the president say about Intel's CEO?   \n",
       "2    What did the president say about gun violence?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The president thanked Justice Stephen Breyer f...   \n",
       "1  The president mentions Intel's CEO, Pat Gelsin...   \n",
       "2  The president asked Congress to pass proven me...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Tonight, I’d like to honor someone who has de...   \n",
       "1  [But that’s just the beginning. \\n\\nIntel’s CE...   \n",
       "2  [And I ask Congress to pass proven measures to...   \n",
       "\n",
       "                                       ground_truths  \\\n",
       "0  [The president said that Justice Breyer has de...   \n",
       "1  [The president said that Pat Gelsinger is read...   \n",
       "2  [The president asked Congress to pass proven m...   \n",
       "\n",
       "                                        ground_truth  context_precision  \\\n",
       "0  The president said that Justice Breyer has ded...               1.00   \n",
       "1  The president said that Pat Gelsinger is ready...               1.00   \n",
       "2  The president asked Congress to pass proven me...               0.75   \n",
       "\n",
       "   context_recall  faithfulness  answer_relevancy  \n",
       "0             1.0      0.333333          0.893595  \n",
       "1             1.0      1.000000          0.902540  \n",
       "2             1.0      1.000000          0.905776  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./df_llama.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
